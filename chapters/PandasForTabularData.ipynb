{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e350f19",
   "metadata": {},
   "source": [
    "# Pandas For Working With Tabular Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c43806",
   "metadata": {},
   "source": [
    "[Pandas](http://pandas.pydata.org/) is a library designed to work with tabular data. It is built on NumPy. Data in pandas is often used to plot with Matplotlib or feed statistical analysis with SciPy. Its ease of use makes it ideal to work with large data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98103c69",
   "metadata": {},
   "source": [
    "```{exercise}\n",
    ":label: my4-exercise1\n",
    "\n",
    "Import pandas. Use convenient naming.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4775570c",
   "metadata": {},
   "source": [
    "````{solution} my4-exercise1\n",
    ":label: my4-solution1\n",
    ":class: dropdown\n",
    "\n",
    "```{code-block} python\n",
    "import pandas as pd\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ac137",
   "metadata": {},
   "source": [
    "## __<font color=blue>DataFrames have a size and shape</font>__\n",
    "---\n",
    "\n",
    "Pandas __Series__ are a one-dimensional labeled array holding data of any type.\n",
    "\n",
    "Pandas __DataFrames__ are structures that contain data organized in two dimensions, _i.e._ __rows__ and __columns__. Both rows and columns have __indices__. Columns can have __labels__ too. \n",
    "\n",
    "DataFrames have a variety of properties:\n",
    "\n",
    "- __size__: the total number of elements\n",
    "- __shape__: the number of units along each dimension\n",
    "\n",
    "```{image} ./Images-PandasForTabularData/Dataframes.png\n",
    ":alt: A DataFrame has rows and columns\n",
    ":width: 600px\n",
    ":align: center\n",
    "```\n",
    "\n",
    "Of note, NumPy arrays and pandas Series have one data type for the entire array or Series while pandas DataFrames have one data type per column. Missing data is shown as `NaN`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7181ce",
   "metadata": {},
   "source": [
    "## __<font color=blue>Creating a DataFrame with nested lists or arrays</font>__\n",
    "---\n",
    "\n",
    "To create a DataFrame, use `pd.DataFrame(data, index, columns)`. Just pass _e.g._ a nested list or a 2D array as data to the DataFrame constructor. The function also has the optional index and column arguments that are used to name the row indices and column labels respectively. By default, both are _(0, 1, 2, â€¦, n)_. If the data contains column labels, the column argument will perform column selection instead.\n",
    "\n",
    "Use `dataframe_name.size` to get the number of elements of a DataFrame as an integer value.\n",
    "\n",
    "Use `dataframe_name.shape` to get the number of rows and columns of a DataFrame as a tuple.\n",
    "\n",
    "Use `dataframe_name.info()` to get more information about a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e876a5b8",
   "metadata": {},
   "source": [
    "```{exercise}\n",
    ":label: my4-exercise2\n",
    "\n",
    "Create a pandas DataFrame for the data below, representing Michaelis-Menten parameters of wild type and mutant enzyme. Print the number of elements, rows and columns of the DataFrame. See what information the `.info()` function provides.\n",
    "\n",
    "| Enzyme      | $k_{cat}$ (1/s) | $K_{m}$ (mM) |\n",
    "| ----------- | ----------- | ----------- |\n",
    "| Wild type   | 21          | 0.54        |\n",
    "| D178N       | 0.11        | 0.21        |\n",
    "| D224G       | 0.05        |             |\n",
    "| E305G       | 19          | 3.2         |\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3dc934",
   "metadata": {},
   "source": [
    "````{solution} my4-exercise2\n",
    ":label: my4-solution2\n",
    ":class: dropdown\n",
    "\n",
    "Here's one possible solution, using a list.\n",
    "\n",
    "```{code-block} python\n",
    "MMdata = [[\"Wild type\",21,0.54],[\"D178N\",0.11,0.21],[\"D224\",0.05,],[\"E305G\",19,3.2]]   #create a 4 x 3 nested list with different data types. The first item (a string) is \"Enzyme\", the second item (a floating point number) is \"kcat\", and the third item (a floating point number) is \"Km\".\n",
    "\n",
    "df_MMdata = pd.DataFrame(MMdata, columns=['Enzyme', 'kcat (1/s)', 'Km (mM)'])   #create a pandas DataFrame from the arr_MMdata array. Use \"Enzyme\", \"kcat (1/s)\", and \"Km (mM)\" as column labels.\n",
    "print(df_MMdata)   #print the DataFrame created\n",
    "\n",
    "print(df_MMdata.size)   #print the number of elements of the bindingsitesdata DataFrame that we created\n",
    "print(df_MMdata.shape)   #print the number of rows and columns of the bindingsitesdata DataFrame that we created\n",
    "df_MMdata.info()   #print more information about the bindingsitesdata DataFrame that we created\n",
    "```\n",
    "\n",
    "`.info()` prints information about a DataFrame including the number of elements, index data types, columns, non-null values, and memory usage. Null values or empty values can be bad when analyzing data.\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c57102",
   "metadata": {},
   "source": [
    "## __<font color=blue>Creating a DataFrame from an Excel file</font>__\n",
    "---\n",
    "\n",
    "We can read in data from __an Excel file__ into Python using pandas with `pd.read_excel(file_name)`. Do not forget to include the file path _(not needed if the file is saved in the directory from which we are running the script!)_ and extension.\n",
    "\n",
    "This function has several arguments. Here, we list commonly used ones:\n",
    "- To read in data from a specific sheet, use the argument `sheet_name`. _Sheet numbers start with zero!_ By default, this is set to `0` and the first sheet is used.\n",
    "- To skip rows at the beginning and end when reading an Excel sheet, use the arguments `skiprows` and `skipfooter`. By default, both are set to `0` and no rows at the beginning and end are skipped.\n",
    "- To only read certain columns when importing an Excel sheet, use the argument `usecols`. _Column numbers start with zero!_ By default, this is set `None` and all columns are parsed.\n",
    "- To specify a specific row as column labels, use the argument `header`. By default, this is set to `0` and the first row of the Excel file (with index 0) is used as column labels.\n",
    "- To label columns when importing an Excel sheet without column names, use the arguments `header=None` and `names=['column_name 1', ... ,'column_name_n']`. To relabel columns when importing an Excel sheet that already contains column names in the first row, use the arguments `header=None`, `skiprows=1`, and `names=['column_name_1', ... ,'column_name_n']`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0982cf5d",
   "metadata": {},
   "source": [
    "````{exercise}\n",
    ":label: my4-exercise3\n",
    " \n",
    "Read in the data file \"ThermalUnfoldingAssay.xlsx\". This Excel file contains 1 sheet, 4 columns, 32 rows with experimental data,  2 rows with column headers, and 1 row with data processing information.\n",
    "\n",
    "```{image} ./Images-PandasForTabularData/DataThermalUnfoldingAssay.png\n",
    ":alt: The Excel file with data from a thermal unfolding assay\n",
    ":width: 600px\n",
    ":align: center\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced923f7",
   "metadata": {},
   "source": [
    "````{solution} my4-exercise3\n",
    ":label: my4-solution3\n",
    ":class: dropdown\n",
    "\n",
    "Here's one possible solution.\n",
    "\n",
    "```{code-block} python\n",
    "dfThermalUnfoldingAssay = pd.read_excel ('../data/ThermalUnfoldingAssay.xlsx',   #create a pandas DataFrame from the filename with file path and extension shown\n",
    "                    sheet_name=0,   #use the first sheet (no need to specifically include this as we use the default setting)\n",
    "                    skiprows=1,   #skip the first row\n",
    "                    usecols=None,   #import all columns (no need to specifically include this as we use the default setting)\n",
    "                    header=0,   #use the column names from the now first row as column labels (no need to specifically include this as we use the default setting)\n",
    "                    skipfooter=1)   #skip the last row\n",
    "\n",
    "print(dfThermalUnfoldingAssay)   #print the DataFrame created\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcf1d40",
   "metadata": {},
   "source": [
    "## __<font color=blue>Creating a DataFrame from a text file</font>__\n",
    "---\n",
    "\n",
    "We can read in data from a text file into Python using pandas with `pd.read_csv(file_name)`. Do not forget to include the file path _(not needed if the file is saved in the directory from which we are running the script!)_ and extension.\n",
    "\n",
    "This function reads __a comma-separated values (csv) file__ into DataFrame object which we can store as a named variable that can be used later. It has several arguments. Here, we list commonly used ones:\n",
    "- To specify the delimiter used in the csv file, use the argument `sep`. By default, this is set to a comma (`\",\"`) for comma-separated data. Use a space (`\" \"`) for space-separated data or a tab (`'\\t'`) for tab-separated data.\n",
    "- To skip rows at the beginning and end when reading a csv file, use the arguments `skiprows` and `skipfooter`. By default, this is set to `0` and no rows at the beginning and end are skipped.\n",
    "- To only read certain columns when importing a csv file, use the argument `usecols`. _Column numbers start with zero!_ By default, this is set to `None` and all columns are parsed.\n",
    "- To specify a specific row as column labels, use the argument `header`. By default, this is set to `0` and the first row of the csv file (with index 0) is used as column labels.\n",
    "- To label columns when importing a csv file without column names, use the arguments `header=None` and `names=['column_name_1', ... ,'column_name_n']`. To relabel columns when importing a csv file that already contains column names in the first row, use the arguments `header=None`, `skiprows=1`, and `names=['column_name_1', ... ,'column_name_n']`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256a9e4e",
   "metadata": {},
   "source": [
    "````{exercise}\n",
    ":label: my4-exercise4\n",
    " \n",
    "Read in the data file \"ProteinAssayStandardCurve.txt\". This text file with tab-separated data contains 2 columns, 8 rows with experimental data,  and 1 row with column headers.\n",
    "\n",
    "```{image} ./Images-PandasForTabularData/DataProteinAssay_StandardCurve.png\n",
    ":alt: The text file with standard curve data for a protein assay\n",
    ":width: 600px\n",
    ":align: center\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3caa070",
   "metadata": {},
   "source": [
    "````{solution} my4-exercise4\n",
    ":label: my4-solution4\n",
    ":class: dropdown\n",
    "\n",
    "Here's one possible solution.\n",
    "\n",
    "```{code-block} python\n",
    "dfProteinAssay = pd.read_csv ('../data/ProteinAssay_StandardCurve.txt',   #create a pandas DataFrame from the filename with file path and extension shown\n",
    "                    sep='\\t',   #the file contains tab-separated data\n",
    "                    skiprows=0,   #skip the first row (no need to specifically include this as we use the default setting)\n",
    "                    usecols=None,   #import all columns (no need to specifically include this as we use the default setting)\n",
    "                    header=0,   #use the column names from the now first row as column labels (no need to specifically include this as we use the default setting)\n",
    "                    skipfooter=0)   #skip the last row (no need to specifically include this as we use the default setting)\n",
    "\n",
    "print (dfProteinAssay)   #print the DataFrame created\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b4e280",
   "metadata": {},
   "source": [
    "## __<font color=blue>Indexing and slicing for DataFrames using `.iloc`</font>__\n",
    "---\n",
    "\n",
    "We can select rows, columns, and positions in a DataFrame using `dataframe_name.iloc[]`. There are two arguments: a row selector, and an optional column selector: `dataframe_name.iloc[row_index, column_index]`. Both accept the zero-based indices of rows and columns.\n",
    "\n",
    "To select an entire row, simply specify the index of the row, _e.g._ `dataframe_name.iloc[0]` to access row 0.\n",
    "\n",
    "To select an entire column, specify the index of the column and provide `:` for the row index, _e.g._ `dataframe_name.iloc[:,0]` to access column 0. Instead of using the `.iloc` method to extract a column, we can also use square brackets with the column name of interest. For example, both `dataframe_name.iloc[:,0]` and `dataframe_name['column_name_1']` give the first column of the DataFrame.\n",
    "\n",
    "We can also use a range for the row index and/or column index to slice multiple elements using: `dataframe_name.iloc[start_index_row:end_index_row, start_index_column:end_index_column]`. We select data from position `start_index` (included) to position `end_index` (excluded)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421d4a7",
   "metadata": {},
   "source": [
    "```{exercise}\n",
    ":label: my4-exercise5\n",
    "\n",
    "Create a pandas DataFrame for the data below.\n",
    "\n",
    "| [Hormone] (nM)  | Fraction of binding sites occupied - protein 1 | Fraction of binding sites occupied - protein 2 |\n",
    "| ----------- | ----------- | ----------- |\n",
    "| 0.2         | 0.048       | 0.291       |\n",
    "| 0.5         | 0.110       | 0.487       |\n",
    "| 1.0         | 0.224       | 0.669       |\n",
    "| 2.0         | 0.467       | 0.732       |\n",
    "| 5.0         | 0.632       | 0.891       |\n",
    "| 10.0        | 0.715       | 0.948       |\n",
    "| 20.0        | 0.832       | 0.971       |\n",
    "| 50.0        | 0.929       | 0.991       |\n",
    "\n",
    "1. Select and show the fraction of binding sites occupied for protein 2 when [Hormone] (nM) = 5.0 nM.\n",
    "2. Select and show the fraction of binding sites occupied for both proteins when [Hormone] (nM) = 5.0 nM.\n",
    "3. Select and show the fraction of binding sites occupied for protein 2 for all [Hormone] (nM). Use two different ways.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152c1ee9",
   "metadata": {},
   "source": [
    "````{solution} my4-exercise5\n",
    ":label: my4-solution5\n",
    ":class: dropdown\n",
    "\n",
    "Here's one possible solution.\n",
    "\n",
    "```{code-block} python\n",
    "arr_bindingsitesdata = np.array([[0.2,0.048,0.291], [0.5,0.110,0.487], [1.0,0.224,0.669], [2.0,0.467,0.732], [5.0,0.632,0.891], [10.0,0.715,0.948], [20.0,0.832,0.971], [50.0,0.929,0.991]])   #create an 8 x 3 array. The first item is \"Hormone] (nM)\", the second item is \"Fraction of binding sites occupied - protein 1\", and the third item is \"Fraction of binding sites occupied - protein 2\".\n",
    "\n",
    "df_bindingsitesdata = pd.DataFrame(arr_bindingsitesdata, columns=['[Hormone] (nM)', 'Protein 1', 'Protein 2'])   #create a pandas DataFrame from the arr_bindingsitesdata array. Use \"Hormone] (nM)\", \"Protein 1\", and \"Protein 2\" as column labels.\n",
    "\n",
    "print(df_bindingsitesdata.iloc[4,2])   #select and print the third element on the fifth row. Remember that indices start from 0!\n",
    "\n",
    "print(df_bindingsitesdata.iloc[4,1:3])   #select and print the second and third elements of the fifth row. Remember that indices start from 0 and that when we specify the end item, it goes up to but does not include that item!\n",
    "\n",
    "print(df_bindingsitesdata.iloc[:,2])   #select and print the third column. Remember that indices start from 0!\n",
    "print(df_bindingsitesdata['Protein 2'])   #select and print the third column. Use the column name.\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ca451d",
   "metadata": {},
   "source": [
    "## __<font color=blue>Manipulating DataFrames: inserting columns</font>__\n",
    "---\n",
    "\n",
    "We use `pd.dataframe_name.insert(loc, column, value)` to __add a new column to an existing DataFrame__. This command has `(loc, column, value)` as input parameters for the insertion index, the column name, and the column values as list or array or ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9c2a15",
   "metadata": {},
   "source": [
    "````{exercise}\n",
    ":label: my4-exercise6\n",
    "\n",
    "Read in the data file \"ProteinAssay_StandardCurve_Triplicates.xlsx\". This Excel file contains 2 sheets, 3 columns, 8 rows with experimental data, and 1 row with column headers.\n",
    "\n",
    "```{image} ./Images-PandasForTabularData/DataProteinAssay_StandardCurve_Triplicates.png\n",
    ":alt: The Excel file with standard curve data, performed in triplicate, for a protein assay\n",
    ":width: 600px\n",
    ":align: center\n",
    "```\n",
    "\n",
    "Insert a column with [BSA] in mg/ml.\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d85330",
   "metadata": {},
   "source": [
    "````{solution} my4-exercise6\n",
    ":label: my4-solution6\n",
    ":class: dropdown\n",
    "\n",
    "Here's one possible solution.\n",
    "\n",
    "```{code-block} python\n",
    "dfProteinAssayTri = pd.read_excel ('../data/ProteinAssay_StandardCurve_Triplicates.xlsx',   #create a pandas DataFrame from the filename with file path and extension shown\n",
    "                    sheet_name=1,   #use the second sheet\n",
    "                    skiprows=0,   #skip no rows (no need to specifically include this as we use the default setting)\n",
    "                    usecols=None,   #import all columns (no need to specifically include this as we use the default setting)\n",
    "                    header=0,   #use the column names from the now first row as column labels (no need to specifically include this as we use the default setting)\n",
    "                    skipfooter=0)   #skip no footers (no need to specifically include this as we use the default setting)\n",
    "\n",
    "print(dfProteinAssayTri)   #print the DataFrame created\n",
    "\n",
    "BSAconc = [0, 0.125, 0.250, 0.500, 0.750, 1.00, 1.50, 2.00]   #create a list with integers containing the BSA concentrations in mg/ml\n",
    "\n",
    "dfProteinAssayTri.insert(0, '[BSA] (mg/ml)', BSAconc)    #insert the column at index 0 (i.e. make it the first column) in dfProteinAssayTri, name the column [BSA], and fill it with the data provided by BSAconc\n",
    "\n",
    "print(dfProteinAssayTri)   #print the DataFrame created\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68065ae3",
   "metadata": {},
   "source": [
    "## __<font color=blue>The axis parameter in mean, standard deviation ...</font>__\n",
    "---\n",
    "\n",
    "Use the `pd.dataframe_name.mean()` and `pd.dataframe_name.std()` functions to calculate the __mean__ and __standard deviation__ of the elements of each column or the elements of each row of a given DataFrame. They contain an `axis` argument, which is the axis for the function to be applied on. With `axis=0`, we calculate the mean along the 0th dimension (rows) and get the mean of elements of each column; with `axis=1`, we calculate the mean along the 1st dimension (columns) and get the mean of the elements of each row.\n",
    "\n",
    "```{image} ./Images-PandasForTabularData/DataframesAxisOperations.png\n",
    ":alt: The text file with standard curve data for a protein assay\n",
    ":width: 600px\n",
    ":align: center\n",
    "```\n",
    "\n",
    "We can select the rows and / or columns we want to include using `dataframe_name.iloc[start_index_row:end_index_row, start_index_column:end_index_column]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0584a8e2",
   "metadata": {},
   "source": [
    "````{exercise}\n",
    ":label: my4-exercise7\n",
    "\n",
    "Use the DataFrame created in the previous exercise and the `pd.dataframe_name.mean()` and `pd.dataframe_name.std()` functions to calculate the mean and standard deviation for the three replicate A562nm measurements for each $[BSA]$ concentration. Store the information in two new columns: 'A562nm (AU) - mean' and 'A562nm (AU) - std'.\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f089312a",
   "metadata": {},
   "source": [
    "````{solution} my4-exercise7\n",
    ":label: my4-solution7\n",
    ":class: dropdown\n",
    "\n",
    "Here's one possible solution.\n",
    "\n",
    "```{code-block} python\n",
    "dfProteinAssayTri['A562nm (AU) - mean'] = dfProteinAssayTri.iloc[:,1:4].mean(axis=1)   #Calculate the mean for each row and store the value in a new column called 'A562nm (AU) - mean'. Use axis 1. Use columns 1 = A562nm (AU) - 1 to 3 = A562nm (AU) - 3, represented by [1:4].\n",
    "dfProteinAssayTri['A562nm (AU) - std'] = dfProteinAssayTri.iloc[:,1:4].std(axis=1)   #Calculate the standard deviation for each row and store the value in a new column called 'A562nm (AU) - std'. Use axis 1. Use columns 1 = A562nm (AU) - 1 to 3 = A562nm (AU) - 3, represented by [1:4].\n",
    "\n",
    "print(dfProteinAssayTri)   #print the DataFrame created\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295229c5",
   "metadata": {},
   "source": [
    "## __<font color=blue>Arithmetic operations for DataFrames</font>__\n",
    "---\n",
    "\n",
    "Arithmetic operations (`+` for addition, `-` for substraction, `*` for multiplication, `/` for division, and `**` for power operations) and NumPy universal functions (such as `n..log10()` and `np.square()`) can be performed on data in a DataFrame and between DataFrames.\n",
    "\n",
    "When two DataFrames share the same row and column indices, operations follow an element-wise behavior, similar to NumPy arrays. \n",
    "When the two items have different shapes, _e.g._ working with a pandas DataFrame and a Pandas series or working with a pandas DataFrame and a scalar, the item with fewer dimensions is broadcasted to match the shape of the larger item, similar to broadcasting NumPy arrays. When the two items have different shapes and their dimensions are not compatible, an error is raised.\n",
    "\n",
    "Arbitrary functions can be applied along the axes of a DataFrame using the `dataframe_name.apply(function_name)` method.  It has several optional arguments. Here, we list commonly used ones:\n",
    "- The required `function_name` parameter takes a function that is executed on the series or dataframe. \n",
    "- The `axis` parameter is used to specify whether rows or columns are taken as input. By default, this is set to `0` and the function is applied to each column.\n",
    "- The `args` parameter passes arguments to the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b69e8d",
   "metadata": {},
   "source": [
    "````{exercise}\n",
    ":label: my4-exercise8\n",
    "\n",
    "For the following data,\n",
    "\n",
    "| Sample     | A280nm - 1  | A280nm - 2  | A280nm - 3  |\n",
    "| ---------- | ----------- | ----------- | ----------- |\n",
    "| Sample 1   | 0.734       | 0.699       | 0.755       |\n",
    "| Sample 2   | 0.457       | 0.489       | 0.511       |\n",
    "| Sample 3   | 0.321       | 0.278       | 0.349       |\n",
    "\n",
    "1. create a Pandas DataFrame,\n",
    "2. calculate the mean for the three replicate A280nm measurements for each sample and store the information in a new column,\n",
    "3. apply the Beer-Lambert law to all samples, use a path length of 1 cm and an extinction coefficient of 43824 $M^{-1} cm^{-1}$. Store the information in a new column.\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c35ba0",
   "metadata": {},
   "source": [
    "````{solution} my4-exercise8\n",
    ":label: my4-solution8\n",
    ":class: dropdown\n",
    "\n",
    "Here's one possible solution.\n",
    "\n",
    "```{code-block} python\n",
    "#Create the pandas DataFrame\n",
    "dataA280nm = [['sample 1', 0.734, 0.699, 0.755],\n",
    "              ['sample 2', 0.457, 0.489, 0.511],\n",
    "              ['sample 3', 0.321, 0.278, 0.349]]   #create a 3 x 4 nested list with different data types. The first item (a string) is \"Sample\", the second to fourth items (floating point numbers) are for \"A280nm - 1\" to \"A280nm - 3\".\n",
    "\n",
    "dfA280nm = pd.DataFrame(dataA280nm, columns=['Sample', 'A280nm - 1', 'A280nm - 2', 'A280nm - 3'])   #create a pandas DataFrame from the dataA280nm nested list. Use \"Sample\" and \"A280nm - 1\" to \"A280nm - 3\" as column labels.\n",
    "  \n",
    "print(dfA280nm)   #print the DataFrame created\n",
    "\n",
    "\n",
    "#Cacluate the means\n",
    "dfA280nm['A280nm - mean'] = dfA280nm.iloc[:,1:4].mean(axis=1)   #calculate the mean for the three replicate A280nm measurements (i.e. columns 1 = \"A280nm - 1\" to 3 = \"A280nm - 3\", represented by [1:4]) for each sample and store the information in a new column called 'A280nm - mean'.\n",
    "\n",
    "print(dfA280nm)   #print the DataFrame created\n",
    "\n",
    "\n",
    "#Calculate the concentrations\n",
    "def beer_lambert(absorbance, epsilon, path_length):   #define the Beer-Lambert function\n",
    "    \"\"\"\n",
    "    Evaluate the concentration of a solution, using the Beer-Lambert law.\n",
    "\n",
    "    Args:\n",
    "        absorbance (float) in AU\n",
    "        epsilon (float) in L/(mol cm)\n",
    "        path_length (float) in cm\n",
    "\n",
    "    Returns:\n",
    "        concentration of the solution (float) in (mol/L)\n",
    "    \"\"\"\n",
    "    concentration = absorbance / (epsilon * path_length)\n",
    "    return concentration\n",
    "\n",
    "dfA280nm['Conc (M)'] = dfA280nm['A280nm - mean'].apply(beer_lambert, args=(43824, 1))   #apply the Beer-Lambert function with arguments 43824, and 1 (after the absorbance value) to the mean of all samples, i.e. 'A280nm - mean' and store the information in a new column called 'Conc (M)'\n",
    "\n",
    "print(dfA280nm)   #print the DataFrame created\n",
    "```\n",
    "````"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
